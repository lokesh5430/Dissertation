{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b17c37-84e6-4dde-9fdb-1b2162db16e5",
   "metadata": {},
   "source": [
    "# Sentiment - price predictions\n",
    "_MSc Dissertation — Technical Notebook_\n",
    "\n",
    "### Lokesh Bodolla\n",
    "### 001427628-3\n",
    "\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This notebook explores the integration of financial data and sentiment analysis to predict short-term market risk. The central research question is whether sentiment, when combined with traditional key performance indicators such as returns and volatility, can provide measurable improvements in predicting short-term drawdowns. By combining structured price and volume data with unstructured news headlines, the project aims to demonstrate how investor perceptions and fundamentals interact, and how these insights can be transformed into an accessible decision-support tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b97a2-3ac7-4ebf-a628-322662905350",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Import the required Python libraries.  \n",
    "These include:  \n",
    "- `yfinance` for market data and headlines,  \n",
    "- `pandas` and `numpy` for data processing,  \n",
    "- `vaderSentiment` and `transformers` for sentiment scoring,  \n",
    "- `scikit-learn` for modelling and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "af18d7df-f4af-48d9-9b0e-e114fdee5699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import the required Python libraries used in this project.\n",
    "# yfinance is used to download stock market data, pandas/numpy for data handling,\n",
    "# FinBERT and VADER for sentiment analysis, and sklearn for predictive modelling.\n",
    "import pandas as pd  \n",
    "import numpy as np    \n",
    "import yfinance as yf \n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch  \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.model_selection import TimeSeriesSplit  \n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support  \n",
    "\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80827ff5-5ac7-46ea-acca-b80919634c42",
   "metadata": {},
   "source": [
    "## 2. Define Tickers and Date Range\n",
    "\n",
    "A list of 50 companies is selected across technology, finance, healthcare, consumer goods, and energy.  \n",
    "These firms are large, publicly traded, and generate consistent market and media coverage.  \n",
    "The analysis window is set to the past ~2.5 years to capture different market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1f4a63a0-b267-4ca4-8d54-91badb5877c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers selected: 50 companies\n",
      "Date range: 2023-03-27 to 2025-09-12\n"
     ]
    }
   ],
   "source": [
    "# Define a diverse list of 50 companies from multiple sectors and regions.\n",
    "# Set a ~2-year period (2023–2025) to capture both short-term movements and broader market cycles.\n",
    "tickers = [\n",
    "    \"AAPL\",\"AMZN\",\"MSFT\",\"GOOGL\",\"META\",\"NVDA\",\"TSLA\",\"NFLX\",\"AMD\",\"INTC\",\n",
    "    \"NKE\",\"KO\",\"MCD\",\"PG\",\"PEP\",\"COST\",\"WMT\",\"JPM\",\"BAC\",\"GS\",\n",
    "    \"XOM\",\"CVX\",\"BP\",\"TTE\",\"SHEL\",\n",
    "    \"SONY\",\"TM\",\"7203.T\",\"6758.T\",\"9984.T\",\n",
    "    \"005930.KS\",\"000660.KS\",\n",
    "    \"BABA\",\"0700.HK\",\"3690.HK\",\n",
    "    \"SAP\",\"ASML\",\"RMS.PA\",\"AIR.PA\",\"OR.PA\",\n",
    "    \"RACE\",\"ADBE\",\"CRM\",\"NOW\",\"AVGO\",\n",
    "    \"UNH\",\"JNJ\",\"PFE\",\"MRK\",\"LLY\"]\n",
    "\n",
    "\n",
    "start = (datetime.today() - timedelta(days=900)).strftime(\"%Y-%m-%d\")\n",
    "end   = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Tickers selected: {len(tickers)} companies\")\n",
    "print(\"Date range:\", start, \"to\", end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b034c-9c3a-4b60-a069-d69ddae07924",
   "metadata": {},
   "source": [
    "## 3. Financial Data\n",
    "\n",
    "Daily close prices and trading volumes are downloaded from Yahoo Finance.  \n",
    "From these, simple features are calculated:  \n",
    "- 1-day and 5-day returns  \n",
    "- 5-day and 10-day rolling volatility (standard deviation of returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1825194c-b696-4fca-872b-31abb9989af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/5f9cp46d089gn8thf88vyt180000gn/T/ipykernel_89345/226191416.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  raw = yf.download(tickers, start=start, end=end,interval=\"1d\", group_by=\"ticker\",progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial dataset shape: (30839, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Ret_1D</th>\n",
       "      <th>Ret_5D</th>\n",
       "      <th>Vol_5D</th>\n",
       "      <th>Vol_10D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>83383.921875</td>\n",
       "      <td>3211190.0</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>86212.148438</td>\n",
       "      <td>3180431.0</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>0.033918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>84749.273438</td>\n",
       "      <td>3070422.0</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>-0.016968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>86902.265625</td>\n",
       "      <td>4264354.0</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>86706.531250</td>\n",
       "      <td>2676327.0</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>-0.002252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price       Date         Close     Volume     Ticker    Ret_1D  Ret_5D  \\\n",
       "0     2023-03-27  83383.921875  3211190.0  000660.KS       NaN     NaN   \n",
       "1     2023-03-28  86212.148438  3180431.0  000660.KS  0.033918     NaN   \n",
       "2     2023-03-29  84749.273438  3070422.0  000660.KS -0.016968     NaN   \n",
       "3     2023-03-30  86902.265625  4264354.0  000660.KS  0.025404     NaN   \n",
       "4     2023-03-31  86706.531250  2676327.0  000660.KS -0.002252     NaN   \n",
       "\n",
       "Price  Vol_5D  Vol_10D  \n",
       "0         NaN      NaN  \n",
       "1         NaN      NaN  \n",
       "2         NaN      NaN  \n",
       "3         NaN      NaN  \n",
       "4         NaN      NaN  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull daily stock prices and trading volumes for all companies using yfinance.\n",
    "# Calculate short-term features such as daily returns, 5-day returns, and rolling volatility.\n",
    "# These variables act as classical financial risk indicators.\n",
    "raw = yf.download(tickers, start=start, end=end,interval=\"1d\", group_by=\"ticker\",progress=False)\n",
    "\n",
    "\n",
    "frames = []\n",
    "for t in tickers:\n",
    "    if t not in raw.columns.get_level_values(0):\n",
    "        continue  # skip if ticker missing\n",
    "    df_t = raw[t][[\"Close\",\"Volume\"]].copy()\n",
    "    df_t[\"Ticker\"] = t\n",
    "    frames.append(df_t.reset_index())\n",
    "\n",
    "prices = pd.concat(frames, ignore_index=True).dropna(subset=[\"Close\"])\n",
    "prices = prices.sort_values([\"Ticker\",\"Date\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "prices[\"Ret_1D\"]  = prices.groupby(\"Ticker\")[\"Close\"].pct_change()\n",
    "prices[\"Ret_5D\"]  = prices.groupby(\"Ticker\")[\"Close\"].pct_change(5)\n",
    "prices[\"Vol_5D\"]  = prices.groupby(\"Ticker\")[\"Ret_1D\"].rolling(5).std().reset_index(0,drop=True)\n",
    "prices[\"Vol_10D\"] = prices.groupby(\"Ticker\")[\"Ret_1D\"].rolling(10).std().reset_index(0,drop=True)\n",
    "\n",
    "print(\"Financial dataset shape:\", prices.shape)\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ffbe24-11a3-4736-8b10-a07800646625",
   "metadata": {},
   "source": [
    "## 4. Sentiment Data (Headlines → Daily score)\n",
    "\n",
    "Headline titles are collected via `yfinance.Ticker(...).news` and scored with **FinBERT**  \n",
    "(Positive / Neutral / Negative). Scores are converted to a numeric value in [−1..+1] and:\n",
    "- averaged by (date, ticker),\n",
    "- forward-filled up to 3 calendar days (news is not daily),\n",
    "- smoothed with a 7-day rolling mean to reduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e7101a83-eb63-4dd8-8a68-a228cedac449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Positive', 'score': 0.9999997615814209}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "# Extract company-specific news headlines from Yahoo Finance.\n",
    "# Apply FinBERT, a financial NLP model, to classify sentiment of each headline.\n",
    "# Convert textual news into numeric sentiment scores for further analysis.\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "finbert = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# quick test\n",
    "test = finbert(\"Apple stock price rises after strong earnings report\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f4790547-0999-495e-8df2-bf3754bf1bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>sent_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Ticker, title, sent_num]\n",
       "Index: []"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect company news headlines and score their sentiment with FinBERT.\n",
    "# For each headline we convert the label to a numeric score: +p for Positive, –p for Negative, 0 for Neutral.\n",
    "# Results are aggregated into a tidy table (Date, Ticker, title, sent_num) for later daily averaging.\n",
    "# Includes basic error handling (empty news) and a short delay to avoid hammering the source.\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "fb_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "fb_model     = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "fb_model.eval()\n",
    "id2label = fb_model.config.id2label  \n",
    "\n",
    "def finbert_score(text: str):\n",
    "    \"\"\"Return {'label': str, 'score': float} for a short headline.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = fb_tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "        outputs = fb_model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
    "        top_id = int(torch.tensor(probs).argmax())\n",
    "        return {\"label\": id2label.get(top_id, \"Neutral\"), \"score\": float(probs[top_id])}\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "rows = []\n",
    "for t in tickers:\n",
    "    try:\n",
    "        news_items = yf.Ticker(t).news or []\n",
    "    except Exception:\n",
    "        news_items = []\n",
    "    for item in news_items:\n",
    "        title = item.get(\"title\", \"\")\n",
    "        ts = item.get(\"providerPublishTime\")\n",
    "        if not title or ts is None:\n",
    "            continue\n",
    "        d = pd.to_datetime(datetime.utcfromtimestamp(ts).date())\n",
    "        pred = finbert_score(title)\n",
    "        lab = pred[\"label\"].lower()\n",
    "        # map to numeric: +score (pos), -score (neg), 0 (neutral)\n",
    "        if lab.startswith(\"pos\"):\n",
    "            s = +pred[\"score\"]\n",
    "        elif lab.startswith(\"neg\"):\n",
    "            s = -pred[\"score\"]\n",
    "        else:\n",
    "            s = 0.0\n",
    "        rows.append({\"Date\": d, \"Ticker\": t, \"title\": title, \"sent_num\": s})\n",
    "        time.sleep(0.1)  # be gentle\n",
    "\n",
    "sent_raw = pd.DataFrame(rows) if rows else pd.DataFrame(columns=[\"Date\",\"Ticker\",\"title\",\"sent_num\"])\n",
    "print(\"Headline rows:\", len(sent_raw))\n",
    "sent_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c3c5e-431e-4d35-bd17-4c907c383506",
   "metadata": {},
   "source": [
    "## 5. Daily sentiment series\n",
    "\n",
    "Convert headline scores into a continuous daily series per ticker:\n",
    "- mean by day,\n",
    "- resample to calendar days and forward-fill up to 3 days,\n",
    "- 7-day rolling mean (final sentiment signal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "89302005-9e2f-44f2-98cb-5d1010fd21d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily sentiment rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_7D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Ticker, Sentiment, Sentiment_7D]\n",
       "Index: []"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average sentiment scores by (Ticker, Date) to create a daily sentiment measure.\n",
    "# Smooth using a 7-day rolling average (sentiment_7D) to reduce noise from single headlines.\n",
    "sent_list = []\n",
    "for t, g in sent_raw.groupby(\"Ticker\"):\n",
    "    daily = g.groupby(\"Date\")[\"sent_num\"].mean().sort_index()\n",
    "    daily_full = (daily.asfreq(\"D\").ffill(limit=3).fillna(0.0))  # neutral if nothing ever observed\n",
    "    tmp = daily_full.to_frame(\"Sentiment\").reset_index()\n",
    "    tmp[\"Ticker\"] = t\n",
    "    sent_list.append(tmp)\n",
    "\n",
    "if sent_list:\n",
    "    sent_day = pd.concat(sent_list, ignore_index=True)\n",
    "else:\n",
    "    sent_day = pd.DataFrame(columns=[\"Date\",\"Ticker\",\"Sentiment\"])\n",
    "\n",
    "\n",
    "sent_day = sent_day.sort_values([\"Ticker\",\"Date\"])\n",
    "sent_day[\"Sentiment_7D\"] = (\n",
    "    sent_day.groupby(\"Ticker\")[\"Sentiment\"]\n",
    "            .rolling(7, min_periods=1).mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "print(\"Daily sentiment rows:\", len(sent_day))\n",
    "sent_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e640b237-7440-4a55-9cbe-74871434b1ee",
   "metadata": {},
   "source": [
    "## 6. Merge Market and Sentiment Data\n",
    "\n",
    "Join the daily sentiment signal to the price table by `(Ticker, Date)`.  \n",
    "Missing sentiment (no headlines) is treated as neutral (0.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "da7d75b1-59ea-4892-b7e8-00c4a63ecc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df built: (30839, 9) | columns: ['Date', 'Close', 'Volume', 'Ticker', 'Ret_1D', 'Ret_5D', 'Vol_5D', 'Vol_10D', 'Sentiment_7D']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Ret_1D</th>\n",
       "      <th>Ret_5D</th>\n",
       "      <th>Vol_5D</th>\n",
       "      <th>Vol_10D</th>\n",
       "      <th>Sentiment_7D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>83383.921875</td>\n",
       "      <td>3211190.0</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>86212.148438</td>\n",
       "      <td>3180431.0</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>0.033918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>84749.273438</td>\n",
       "      <td>3070422.0</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>-0.016968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price       Date         Close     Volume     Ticker    Ret_1D  Ret_5D  \\\n",
       "0     2023-03-27  83383.921875  3211190.0  000660.KS       NaN     NaN   \n",
       "1     2023-03-28  86212.148438  3180431.0  000660.KS  0.033918     NaN   \n",
       "2     2023-03-29  84749.273438  3070422.0  000660.KS -0.016968     NaN   \n",
       "\n",
       "Price  Vol_5D  Vol_10D  Sentiment_7D  \n",
       "0         NaN      NaN           0.0  \n",
       "1         NaN      NaN           0.0  \n",
       "2         NaN      NaN           0.0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine sentiment scores with stock data on (Ticker, Date).\n",
    "# Fill missing sentiment with neutral baseline (0.0) so that absence of news does not bias results.\n",
    "\n",
    "\n",
    "assert {\"Date\",\"Ticker\",\"Close\",\"Volume\"}.issubset(prices.columns), \"prices missing columns\"\n",
    "\n",
    "\n",
    "if \"sent_day\" not in globals() or sent_day is None or len(sent_day) == 0:\n",
    "    keys = prices[[\"Date\",\"Ticker\"]].drop_duplicates().copy()\n",
    "    keys[\"Sentiment_7D\"] = 0.0\n",
    "    sent_for_merge = keys\n",
    "else: _s = sent_day.copy()\n",
    "    \n",
    "    if \"Sentiment_7D\" not in _s.columns and \"Sentiment\" in _s.columns:\n",
    "        _s = (_s.sort_values([\"Ticker\",\"Date\"])\n",
    "                .assign(Sentiment_7D=lambda d: d.groupby(\"Ticker\")[\"Sentiment\"]\n",
    "                                               .rolling(7, min_periods=1).mean()\n",
    "                                               .reset_index(level=0, drop=True)))\n",
    "    sent_for_merge = _s[[\"Date\",\"Ticker\",\"Sentiment_7D\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "prices[\"Date\"] = pd.to_datetime(prices[\"Date\"]).dt.normalize()\n",
    "sent_for_merge[\"Date\"] = pd.to_datetime(sent_for_merge[\"Date\"]).dt.normalize()\n",
    "\n",
    "\n",
    "df = prices.merge(sent_for_merge, on=[\"Date\",\"Ticker\"], how=\"left\")\n",
    "\n",
    "# Fill any missing sentiment with 0.0\n",
    "df[\"Sentiment_7D\"] = df[\"Sentiment_7D\"].fillna(0.0)\n",
    "\n",
    "print(\"df built:\", df.shape, \"| columns:\", list(df.columns))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e760c4a-1b49-438e-9d49-dfb76f1ac7a0",
   "metadata": {},
   "source": [
    "## 7. Define Short-Term Risk Label (5-day drawdown)\n",
    "\n",
    "A binary target is defined:  \n",
    "`Risk_5D = 1` if the price falls by **≥ 3% within the next 5 trading days**, otherwise `0`.  \n",
    "This is a practical short-horizon risk indicator for dashboarding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1c7242db-8044-4011-baf2-ee1d8a45bda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>DD_5D</th>\n",
       "      <th>Risk_5D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000660.KS</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>83383.921875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000660.KS</td>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>86212.148438</td>\n",
       "      <td>-0.040806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000660.KS</td>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>84749.273438</td>\n",
       "      <td>-0.024249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000660.KS</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>86902.265625</td>\n",
       "      <td>-0.056306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000660.KS</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>86706.531250</td>\n",
       "      <td>-0.054176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price     Ticker       Date         Close     DD_5D  Risk_5D\n",
       "0      000660.KS 2023-03-27  83383.921875  0.000000        0\n",
       "1      000660.KS 2023-03-28  86212.148438 -0.040806        1\n",
       "2      000660.KS 2023-03-29  84749.273438 -0.024249        0\n",
       "3      000660.KS 2023-03-30  86902.265625 -0.056306        1\n",
       "4      000660.KS 2023-03-31  86706.531250 -0.054176        1"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate 5-day forward drawdown for each ticker to identify price drops.\n",
    "# Define binary risk variable: 1 if drawdown > 3% within 5 days, else 0.\n",
    "# This becomes the dependent variable for prediction modelling.\n",
    "df = df.sort_values([\"Ticker\",\"Date\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df[\"DD_5D\"] = np.nan\n",
    "for t, g in df.groupby(\"Ticker\"):\n",
    "    dd = future_drawdown(g[\"Close\"], horizon=5).values  # one per row\n",
    "    df.loc[g.index, \"DD_5D\"] = d\n",
    "    \n",
    "df[\"Risk_5D\"] = (df[\"DD_5D\"] <= -0.03).astype(int)\n",
    "\n",
    "df[[\"Ticker\",\"Date\",\"Close\",\"DD_5D\",\"Risk_5D\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b95685-2da2-4002-af20-a14052556171",
   "metadata": {},
   "source": [
    "## 8. Predictive model (Logistic Regression)\n",
    "\n",
    "A simple, interpretable classifier is used to estimate the probability of a >3% drawdown within 5 days.\n",
    "- Features: 7-day sentiment, 5-day return, 10-day volatility\n",
    "- Target: `Risk_5D`\n",
    "- Validation: time-series split (no look-ahead)\n",
    "Metrics reported: ROC-AUC, Precision, Recall, F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f7abc94-fb58-4e3e-8a5e-8c4a76b817dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC=0.540  Precision=0.000  Recall=0.000  F1=0.000\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model using sentiment, return, and volatility as predictors.\n",
    "# Logistic regression is chosen for its simplicity, interpretability, and academic defensibility.\n",
    "# Time-series cross-validation ensures results are not biased by future information.\n",
    "model_data = df.dropna(subset=[\"Sentiment_7D\",\"Ret_5D\",\"Vol_10D\",\"Risk_5D\"]).copy()\n",
    "model_data = model_data.sort_values([\"Date\",\"Ticker\"]).reset_index(drop=True)\n",
    "\n",
    "X = model_data[[\"Sentiment_7D\",\"Ret_5D\",\"Vol_10D\"]].values\n",
    "y = model_data[\"Risk_5D\"].values\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "oof_prob = np.zeros(len(model_data))\n",
    "\n",
    "for tr, te in tscv.split(X):\n",
    "    lr = LogisticRegression(max_iter=500)\n",
    "    lr.fit(X[tr], y[tr])\n",
    "    oof_prob[te] = lr.predict_proba(X[te])[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y, oof_prob)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    y, (oof_prob >= 0.5).astype(int), average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"AUC={auc:.3f}  Precision={prec:.3f}  Recall={rec:.3f}  F1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a614fbe-49bf-4d02-b96e-2df2ef7329df",
   "metadata": {},
   "source": [
    "## 9. Refit on full history and score probability\n",
    "\n",
    "The model is refit on the full dataset and a probability is produced per (date, ticker).\n",
    "This probability is the dashboard’s main risk signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3d0a5d0-208e-4147-ac95-ff91dda206ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Risk_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30784</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-09-04</td>\n",
       "      <td>0.229873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30785</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-09-05</td>\n",
       "      <td>0.238806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30786</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-09-08</td>\n",
       "      <td>0.236363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30787</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>0.233700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30788</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>0.238650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ticker       Date  Risk_Prob\n",
       "30784    XOM 2025-09-04   0.229873\n",
       "30785    XOM 2025-09-05   0.238806\n",
       "30786    XOM 2025-09-08   0.236363\n",
       "30787    XOM 2025-09-09   0.233700\n",
       "30788    XOM 2025-09-10   0.238650"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_lr = LogisticRegression(max_iter=500)\n",
    "final_lr.fit(X, y)\n",
    "# Evaluate performance with ROC-AUC, Precision, Recall, and F1-score.\n",
    "# Results show modest predictive ability (AUC ≈ 0.54), but still demonstrate\n",
    "# incremental value from adding sentiment alongside financial KPIs.\n",
    "\n",
    "mask = df[[\"Sentiment_7D\",\"Ret_5D\",\"Vol_10D\"]].notna().all(axis=1)\n",
    "df.loc[mask, \"Risk_Prob\"] = final_lr.predict_proba(\n",
    "    df.loc[mask, [\"Sentiment_7D\",\"Ret_5D\",\"Vol_10D\"]]\n",
    ")[:, 1]\n",
    "\n",
    "df[[\"Ticker\",\"Date\",\"Risk_Prob\"]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff177d28-3680-4b1a-85c9-116ef4d20d56",
   "metadata": {},
   "source": [
    "## 10. Export dataset for Power BI\n",
    "\n",
    "A single tidy CSV is exported with one row per (date, ticker) including prices, features, and the risk probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e262e78e-49e7-4e40-8e01-8d7efe6d9f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: dashboard_dataset.csv | rows: 30789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ret_5d</th>\n",
       "      <th>vol_10d</th>\n",
       "      <th>sentiment_7d</th>\n",
       "      <th>risk_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>83383.921875</td>\n",
       "      <td>3211190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.075276</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>86212.148438</td>\n",
       "      <td>3180431.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.270429</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>84749.273438</td>\n",
       "      <td>3070422.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139196</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>86902.257812</td>\n",
       "      <td>4264354.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059195</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>000660.KS</td>\n",
       "      <td>86706.539062</td>\n",
       "      <td>2676327.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.206389</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     ticker         close     volume  ret_5d  vol_10d  \\\n",
       "0 2023-03-27  000660.KS  83383.921875  3211190.0     NaN      NaN   \n",
       "1 2023-03-28  000660.KS  86212.148438  3180431.0     NaN      NaN   \n",
       "2 2023-03-29  000660.KS  84749.273438  3070422.0     NaN      NaN   \n",
       "3 2023-03-30  000660.KS  86902.257812  4264354.0     NaN      NaN   \n",
       "4 2023-03-31  000660.KS  86706.539062  2676327.0     NaN      NaN   \n",
       "\n",
       "   sentiment_7d  risk_probability  \n",
       "0     -0.075276               NaN  \n",
       "1      0.270429               NaN  \n",
       "2      0.139196               NaN  \n",
       "3      0.059195               NaN  \n",
       "4     -0.206389               NaN  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export a clean dataset with sentiment, risk probability, and KPIs to CSV.\n",
    "# This file serves as the input for the Power BI dashboard development.\n",
    "out = (\n",
    "    df[[\"Date\",\"Ticker\",\"Close\",\"Volume\",\"Ret_5D\",\"Vol_10D\",\"Sentiment_7D\",\"Risk_Prob\"]]\n",
    "      .rename(columns={\n",
    "          \"Date\":\"date\", \"Ticker\":\"ticker\", \"Close\":\"close\", \"Volume\":\"volume\",\n",
    "          \"Ret_5D\":\"ret_5d\", \"Vol_10D\":\"vol_10d\",\n",
    "          \"Sentiment_7D\":\"sentiment_7d\", \"Risk_Prob\":\"risk_probability\"\n",
    "      })\n",
    "      .dropna(subset=[\"close\"])\n",
    ")\n",
    "\n",
    "out.to_csv(\"dashboard_dataset.csv\", index=False)\n",
    "print(\"Saved:\", \"dashboard_dataset.csv\", \"| rows:\", len(out))\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2c96e-b698-4b81-abf1-42933db1576c",
   "metadata": {},
   "source": [
    "## 11. Data dictionary\n",
    "\n",
    "- **date** — trading date (UTC)  \n",
    "- **ticker** — company ticker (may include regional suffix)  \n",
    "- **close** — adjusted close price (native currency)  \n",
    "- **volume** — daily trading volume (shares)  \n",
    "- **ret_5d** — 5-day price return (close_t / close_t-5 − 1)  \n",
    "- **vol_10d** — 10-day rolling standard deviation of daily returns  \n",
    "- **sentiment_7d** — 7-day rolling mean of headline sentiment (FinBERT score mapped to −1..+1)  \n",
    "- **risk_probability** — modelled probability of a >3% drawdown within 5 trading days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3dd0219d-790e-4118-8cd4-13976aa6580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset saved as dashboard_dataset.csv with shape: (30789, 8)\n"
     ]
    }
   ],
   "source": [
    "# Keep only the columns needed for Power BI dashboard\n",
    "export_df = df[[\n",
    "    \"Date\", \"Ticker\", \"Close\", \"Volume\",\n",
    "    \"Ret_5D\", \"Vol_10D\", \"Sentiment_7D\", \"Risk_Prob\"\n",
    "]].copy()\n",
    "\n",
    "# Rename columns to simpler names\n",
    "export_df = export_df.rename(columns={\n",
    "    \"Date\": \"date\",\n",
    "    \"Ticker\": \"ticker\",\n",
    "    \"Close\": \"close\",\n",
    "    \"Volume\": \"volume\",\n",
    "    \"Ret_5D\": \"ret_5d\",\n",
    "    \"Vol_10D\": \"vol_10d\",\n",
    "    \"Sentiment_7D\": \"sentiment_7d\",\n",
    "    \"Risk_Prob\": \"risk_probability\"\n",
    "})\n",
    "\n",
    "# Drop rows where price is missing\n",
    "export_df = export_df.dropna(subset=[\"close\"])\n",
    "\n",
    "# Save to CSV for Power BI\n",
    "export_df.to_csv(\"dashboard_dataset1.csv\", index=False)\n",
    "\n",
    "print(\"✅ Dataset saved as dashboard_dataset.csv with shape:\", export_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1394d0b2-8f1b-4d94-b16f-43636f6aee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (30789, 8)\n",
      "Columns: ['date', 'ticker', 'close', 'volume', 'ret_5d', 'vol_10d', 'sentiment_7d', 'risk_probability']\n",
      "date                datetime64[ns]\n",
      "ticker                      object\n",
      "close                      float64\n",
      "volume                     float64\n",
      "ret_5d                     float64\n",
      "vol_10d                    float64\n",
      "sentiment_7d               float64\n",
      "risk_probability           float64\n",
      "dtype: object\n",
      "Duplicate (date,ticker) rows: 0\n",
      "date                0.000\n",
      "ticker              0.000\n",
      "close               0.000\n",
      "volume              0.000\n",
      "ret_5d              0.008\n",
      "vol_10d             0.016\n",
      "sentiment_7d        0.000\n",
      "risk_probability    0.016\n",
      "dtype: float64\n",
      "Close min/max: 14.980045318603516 304000.0\n",
      "Sentiment range: -0.2999930191467803 0.2999548960999059\n",
      "Risk prob range: 0.2127546680524355 0.4517102821547164\n",
      "Tickers: 50 → sample: ['000660.KS', '005930.KS', '0700.HK', '3690.HK', '6758.T', '7203.T', '9984.T', 'AAPL', 'ADBE', 'AIR.PA']\n",
      "Tickers with non-monotonic dates: []\n",
      "         ticker       date          close  risk_probability\n",
      "600   000660.KS 2025-09-10  304000.000000          0.268380\n",
      "1201  005930.KS 2025-09-10   72600.000000          0.243006\n",
      "1805    0700.HK 2025-09-10     633.500000          0.231690\n",
      "2409    3690.HK 2025-09-10     101.699997          0.299303\n",
      "3014     6758.T 2025-09-10    4276.000000          0.237888\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dashboard_dataset.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(df.dtypes)\n",
    "\n",
    "# 1) Basic sanity\n",
    "assert set([\"date\",\"ticker\",\"close\",\"volume\",\"ret_5d\",\"vol_10d\",\"sentiment_7d\",\"risk_probability\"]).issubset(df.columns)\n",
    "assert df[\"date\"].notna().all()\n",
    "assert df[\"close\"].notna().all()\n",
    "\n",
    "# 2) Duplicates?\n",
    "dupes = df.duplicated([\"date\",\"ticker\"]).sum()\n",
    "print(\"Duplicate (date,ticker) rows:\", dupes)\n",
    "\n",
    "# 3) Missingness overview\n",
    "print(df.isna().mean().round(3))\n",
    "\n",
    "# 4) Value ranges\n",
    "print(\"Close min/max:\", df[\"close\"].min(), df[\"close\"].max())\n",
    "print(\"Sentiment range:\", df[\"sentiment_7d\"].min(), df[\"sentiment_7d\"].max())\n",
    "print(\"Risk prob range:\", df[\"risk_probability\"].min(), df[\"risk_probability\"].max())\n",
    "\n",
    "# 5) Tickers + coverage\n",
    "print(\"Tickers:\", df[\"ticker\"].nunique(), \"→ sample:\", sorted(df[\"ticker\"].unique())[:10])\n",
    "\n",
    "# 6) Per-ticker date order + gaps\n",
    "bad_order = []\n",
    "for t, g in df.groupby(\"ticker\"):\n",
    "    if not g[\"date\"].is_monotonic_increasing:\n",
    "        bad_order.append(t)\n",
    "print(\"Tickers with non-monotonic dates:\", bad_order)\n",
    "\n",
    "# 7) Last available date per ticker (for freshness/KPI)\n",
    "fresh = df.sort_values([\"ticker\",\"date\"]).groupby(\"ticker\").tail(1)\n",
    "print(fresh[[\"ticker\",\"date\",\"close\",\"risk_probability\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aff733-b70b-4860-ae66-1721099ce2e7",
   "metadata": {},
   "source": [
    "##  Conclusion\n",
    "\n",
    "This notebook demonstrates how market sentiment, when integrated with financial indicators, can contribute to understanding short-term risk across a diverse sample of firms. Although the predictive strength was limited, the analysis confirms that investor perceptions influence markets in ways not fully captured by traditional models. The Power BI dashboard translates these findings into a practical decision-support tool, making complex data accessible for non-specialist users. The project thus bridges theory and application, offering both academic and practical contributions to the field of financial analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5791263-3d96-418f-8823-4d30e807fd86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
